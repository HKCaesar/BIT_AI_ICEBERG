{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# turning off my piece of fucking shit GPU\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "# -----\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, ZeroPadding2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As for the data\n",
    "133 out of 1603 examples are missing on 'inc_angle' value.  \n",
    "#### All of them are ships!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_temp = pd.read_json('train.json')\n",
    "sum = 0\n",
    "list = []\n",
    "for i in range(len(data_temp['inc_angle'])):\n",
    "    if data_temp['inc_angle'][i] == \"na\":\n",
    "        sum += 1\n",
    "        list.append(i)\n",
    "print(\"Number of datapoints with missing \\'inc_angle\\':\", sum, \"\\n\\n\")\n",
    "print(\"List of indices:\\n\\n\", list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, half-hearted attempt\n",
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def channels(data):\n",
    "    rgb_arrays = []\n",
    "    for i, row in data.iterrows():\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = band_1 + band_2  # maybe divide instead of adding?\n",
    "\n",
    "        rgb = np.dstack((band_1, band_2, band_3))\n",
    "        rgb_arrays.append(rgb)\n",
    "    return np.array(rgb_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_json('train.json')\n",
    "Y = X['is_iceberg']  # labels\n",
    "\n",
    "X = channels(X)\n",
    "Y = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1363, 75, 75, 3)\n",
      "(241, 75, 75, 3)\n",
      "(1363, 2)\n",
      "(241, 2)\n"
     ]
    }
   ],
   "source": [
    "image_height = 75\n",
    "image_width = 75\n",
    "channels = 3\n",
    "number_of_classes = 2\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 32\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.15)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Conv2D(32, (3, 3), activation='relu', input_shape=(image_width, image_height, channels)))\n",
    "\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model1.add(Flatten())\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(256, activation='relu', use_bias=True, bias_initializer='zeros'))\n",
    "\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Dense(number_of_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1363 samples, validate on 241 samples\n",
      "Epoch 1/1\n",
      "1363/1363 [==============================] - 229s 168ms/step - loss: 1.4073 - acc: 0.7029 - val_loss: 7.1455 - val_acc: 0.5187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff280648a58>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, Y_train,\n",
    "              batch_size=batch_size, validation_data=(X_test, Y_test),\n",
    "              epochs=epochs,\n",
    "                shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
